{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80521d65",
   "metadata": {},
   "source": [
    "# Milano Mobile Traffic Prediction — End-to-End\n",
    "Bu notebook, Milano CDR verisi ile kısa vadeli mobil internet trafiğini tahmin etmek için uçtan uca veri hazırlama, özellik çıkarımı, modelleme ve değerlendirmeyi içerir.\n",
    "\n",
    "Adımlar:\n",
    "- Veri hazırlama (eksik/duplike temizliği, birleştirme)\n",
    "- Özellik mühendisliği (zaman, lag/rolling, döngüsel kodlama)\n",
    "- Baseline modeller (Naive = lag_1, Moving Average)\n",
    "- ML modeller (RandomForest; opsiyonel: XGBoost)\n",
    "- Zaman-temelli ayrım, metrikler (MAE, RMSE, R²), görseller ve artefaktlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47d045ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT     : /Users/hamza/Documents/MobilCom/mobile_dataset\n",
      "RAW      : /Users/hamza/Documents/MobilCom/mobile_dataset/data/raw\n",
      "PROCESSED: /Users/hamza/Documents/MobilCom/mobile_dataset/data/processed\n",
      "RESULTS  : /Users/hamza/Documents/MobilCom/mobile_dataset/results\n"
     ]
    }
   ],
   "source": [
    "# Setup & Paths\n",
    "import os, sys, runpy, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# Resolve project root (works if run from scripts/ or project root)\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name == 'scripts' and (ROOT.parent / 'data').exists():\n",
    "    ROOT = ROOT.parent\n",
    "elif (ROOT / 'scripts').exists() and (ROOT / 'data').exists():\n",
    "    pass\n",
    "\n",
    "DATA_RAW = ROOT / 'data' / 'raw'\n",
    "DATA_PROCESSED = ROOT / 'data' / 'processed'\n",
    "RESULTS = ROOT / 'results'\n",
    "SCRIPTS = ROOT / 'scripts'\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROCESSED_FILE = DATA_PROCESSED / 'milano_internet_combined.csv'\n",
    "FEATURES_FILE  = DATA_PROCESSED / 'milano_features.csv'\n",
    "\n",
    "print('ROOT     :', ROOT)\n",
    "print('RAW      :', DATA_RAW)\n",
    "print('PROCESSED:', DATA_PROCESSED)\n",
    "print('RESULTS  :', RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a97cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: processed CSV exists\n",
      "OK: features CSV exists\n"
     ]
    }
   ],
   "source": [
    "# Build processed/feature data if missing\n",
    "if not PROCESSED_FILE.exists():\n",
    "    print('Processed CSV not found → running prepare_data.py')\n",
    "    runpy.run_path(str(SCRIPTS / 'prepare_data.py'), run_name='__main__')\n",
    "else:\n",
    "    print('OK: processed CSV exists')\n",
    "\n",
    "if not FEATURES_FILE.exists():\n",
    "    print('Features CSV not found → running feature_engineering.py')\n",
    "    runpy.run_path(str(SCRIPTS / 'feature_engineering.py'), run_name='__main__')\n",
    "else:\n",
    "    print('OK: features CSV exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed880196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1619994 Cols: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_interval</th>\n",
       "      <th>square_id</th>\n",
       "      <th>internet_traffic</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>dow_sin</th>\n",
       "      <th>dow_cos</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>roll_mean_3</th>\n",
       "      <th>roll_mean_6</th>\n",
       "      <th>roll_mean_12</th>\n",
       "      <th>roll_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>35.4161</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>34.8416</td>\n",
       "      <td>31.3769</td>\n",
       "      <td>57.7990</td>\n",
       "      <td>33.080200</td>\n",
       "      <td>40.382267</td>\n",
       "      <td>40.382267</td>\n",
       "      <td>9.832804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>42.9335</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>35.4161</td>\n",
       "      <td>34.8416</td>\n",
       "      <td>44.0469</td>\n",
       "      <td>33.878200</td>\n",
       "      <td>36.651783</td>\n",
       "      <td>39.672814</td>\n",
       "      <td>4.924253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>59.8808</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>42.9335</td>\n",
       "      <td>35.4161</td>\n",
       "      <td>41.2071</td>\n",
       "      <td>37.730400</td>\n",
       "      <td>36.466217</td>\n",
       "      <td>40.080400</td>\n",
       "      <td>4.600151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>71.1355</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>59.8808</td>\n",
       "      <td>42.9335</td>\n",
       "      <td>33.0221</td>\n",
       "      <td>46.076800</td>\n",
       "      <td>39.578500</td>\n",
       "      <td>42.280444</td>\n",
       "      <td>10.709396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>81.7390</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>71.1355</td>\n",
       "      <td>59.8808</td>\n",
       "      <td>31.3769</td>\n",
       "      <td>57.983267</td>\n",
       "      <td>45.930733</td>\n",
       "      <td>45.165950</td>\n",
       "      <td>16.026281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_interval  square_id  internet_traffic  hour  minute  day_of_week  \\\n",
       "0 2013-11-01 06:00:00          1           35.4161     6       0            4   \n",
       "1 2013-11-01 07:00:00          1           42.9335     7       0            4   \n",
       "2 2013-11-01 08:00:00          1           59.8808     8       0            4   \n",
       "3 2013-11-01 09:00:00          1           71.1355     9       0            4   \n",
       "4 2013-11-01 10:00:00          1           81.7390    10       0            4   \n",
       "\n",
       "   is_weekend  hour_sin      hour_cos   dow_sin   dow_cos    lag_1    lag_2  \\\n",
       "0           0  1.000000  6.123234e-17 -0.433884 -0.900969  34.8416  31.3769   \n",
       "1           0  0.965926 -2.588190e-01 -0.433884 -0.900969  35.4161  34.8416   \n",
       "2           0  0.866025 -5.000000e-01 -0.433884 -0.900969  42.9335  35.4161   \n",
       "3           0  0.707107 -7.071068e-01 -0.433884 -0.900969  59.8808  42.9335   \n",
       "4           0  0.500000 -8.660254e-01 -0.433884 -0.900969  71.1355  59.8808   \n",
       "\n",
       "     lag_6  roll_mean_3  roll_mean_6  roll_mean_12  roll_std_6  \n",
       "0  57.7990    33.080200    40.382267     40.382267    9.832804  \n",
       "1  44.0469    33.878200    36.651783     39.672814    4.924253  \n",
       "2  41.2071    37.730400    36.466217     40.080400    4.600151  \n",
       "3  33.0221    46.076800    39.578500     42.280444   10.709396  \n",
       "4  31.3769    57.983267    45.930733     45.165950   16.026281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2013-11-01 06:00:00 → 2013-11-07 23:00:00\n",
      "Cells: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load features (may take time due to size)\n",
    "df = pd.read_csv(FEATURES_FILE)\n",
    "df['time_interval'] = pd.to_datetime(df['time_interval'])\n",
    "df = df.sort_values(['square_id','time_interval']).reset_index(drop=True)\n",
    "print('Rows:', len(df), 'Cols:', len(df.columns))\n",
    "display(df.head())\n",
    "print('Date range:', df['time_interval'].min(), '→', df['time_interval'].max())\n",
    "print('Cells:', df['square_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2baff9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/hamza/Documents/MobilCom/mobile_dataset/results/avg_traffic_over_time.png\n",
      "Saved: /Users/hamza/Documents/MobilCom/mobile_dataset/results/traffic_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Quick EDA\n",
    "plt.figure(figsize=(12,4))\n",
    "mean_ts = df.groupby('time_interval')['internet_traffic'].mean().reset_index()\n",
    "plt.plot(mean_ts['time_interval'], mean_ts['internet_traffic'], color='tab:orange')\n",
    "plt.title('Average Internet Traffic Over Time')\n",
    "plt.xlabel('Time'); plt.ylabel('Avg Traffic'); plt.grid(True); plt.tight_layout()\n",
    "p1 = RESULTS / 'avg_traffic_over_time.png'\n",
    "plt.savefig(p1); plt.close(); print('Saved:', p1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df['internet_traffic'], bins=50)\n",
    "plt.title('Distribution of Internet Traffic')\n",
    "plt.tight_layout()\n",
    "p2 = RESULTS / 'traffic_distribution.png'\n",
    "plt.savefig(p2); plt.close(); print('Saved:', p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90b6191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut time: 2013-11-06 15:00:00\n",
      "Train rows: 1289995 Test rows: 329999\n",
      "Feature count: 15\n"
     ]
    }
   ],
   "source": [
    "# Time-based split (last 20% as test)\n",
    "unique_times = df['time_interval'].sort_values().unique()\n",
    "cut_idx = int(len(unique_times)*0.8)\n",
    "cut_time = unique_times[cut_idx]\n",
    "print('Cut time:', cut_time)\n",
    "\n",
    "train_df = df[df['time_interval'] < cut_time].copy()\n",
    "test_df  = df[df['time_interval'] >= cut_time].copy()\n",
    "print('Train rows:', len(train_df), 'Test rows:', len(test_df))\n",
    "\n",
    "target = 'internet_traffic'\n",
    "drop_cols = ['time_interval','square_id', target]\n",
    "features = [c for c in df.columns if c not in drop_cols]\n",
    "print('Feature count:', len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0627aedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast mode: True | sample frac: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Fast mode toggle (speeds up training/iteration)\n",
    "FAST_TRAIN = True           # set False for full training\n",
    "FAST_SAMPLE_FRAC = 0.25      # use 50% of training rows when FAST_TRAIN\n",
    "print('Fast mode:', FAST_TRAIN, '| sample frac:', FAST_SAMPLE_FRAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65ff3134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline lag_1 → MAE=62.8069 RMSE=171.3403 R²=0.9650\n"
     ]
    }
   ],
   "source": [
    "# Baseline 1: Naive (lag_1)\n",
    "if 'lag_1' in features:\n",
    "    y_pred_b = test_df['lag_1'].to_numpy()\n",
    "    y_true   = test_df[target].to_numpy()\n",
    "    mae_b  = mean_absolute_error(y_true, y_pred_b)\n",
    "    rmse_b = np.sqrt(mean_squared_error(y_true, y_pred_b))\n",
    "    r2_b   = r2_score(y_true, y_pred_b)\n",
    "    print(f'Baseline lag_1 → MAE={mae_b:.4f} RMSE={rmse_b:.4f} R²={r2_b:.4f}')\n",
    "else:\n",
    "    print('lag_1 not found; skipping baseline.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa185998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovingAverage(3) → MAE=91.5670 RMSE=261.7854 R²=0.9183\n",
      "MovingAverage(6) → MAE=129.1227 RMSE=374.5573 R²=0.8327\n",
      "MovingAverage(12) → MAE=129.1227 RMSE=374.5573 R²=0.8327\n"
     ]
    }
   ],
   "source": [
    "# Baseline 2: Moving Average (last k lags)\n",
    "def moving_average_pred(g, k=3):\n",
    "    # Prefer shifted rolling mean columns (non-leaky)\n",
    "    col = f'roll_mean_{k}'\n",
    "    if col in g.columns:\n",
    "        return g[col].to_numpy()\n",
    "    # Fallback: average of available lag_1..lag_k\n",
    "    lag_cols = [f'lag_{i}' for i in [1,2,3,4,5,6] if f'lag_{i}' in g.columns and i<=k]\n",
    "    if lag_cols:\n",
    "        return g[lag_cols].mean(axis=1).to_numpy()\n",
    "    # Worst-case fallback\n",
    "    return np.full(len(g), g['internet_traffic'].mean())\n",
    "\n",
    "ma_metrics = {}\n",
    "for k in [3,6,12]:\n",
    "    y_pred_ma = moving_average_pred(test_df, k=min(k,6))\n",
    "    y_true    = test_df[target].to_numpy()\n",
    "    mae = mean_absolute_error(y_true, y_pred_ma)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred_ma))\n",
    "    r2 = r2_score(y_true, y_pred_ma)\n",
    "    ma_metrics[k] = { 'mae': float(mae), 'rmse': float(rmse), 'r2': float(r2) }\n",
    "    print(f'MovingAverage({k}) → MAE={mae:.4f} RMSE={rmse:.4f} R²={r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1089006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAST] Subsampled train: 322498/1289995 rows\n",
      "RandomForest → MAE=50.4265 RMSE=134.2992 R²=0.9785\n"
     ]
    }
   ],
   "source": [
    "# Train RandomForestRegressor\n",
    "X_train = train_df[features].values\n",
    "y_train = train_df[target].values\n",
    "X_test  = test_df[features].values\n",
    "y_test  = test_df[target].values\n",
    "\n",
    "# Fast mode controls\n",
    "try:\n",
    "    FAST_TRAIN\n",
    "except NameError:\n",
    "    FAST_TRAIN = False\n",
    "FAST_SAMPLE_FRAC = globals().get('FAST_SAMPLE_FRAC', 1.0)\n",
    "\n",
    "# Optional subsampling for faster iteration\n",
    "if FAST_TRAIN and 0.0 < FAST_SAMPLE_FRAC < 1.0:\n",
    "    import numpy as np\n",
    "    rs = np.random.RandomState(42)\n",
    "    n = len(X_train)\n",
    "    k = max(1, int(n * FAST_SAMPLE_FRAC))\n",
    "    idx = rs.choice(n, size=k, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    print(f\"[FAST] Subsampled train: {k}/{n} rows\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100 if FAST_TRAIN else 200,\n",
    "    max_depth=12 if FAST_TRAIN else None,\n",
    "    min_samples_leaf=5 if FAST_TRAIN else 1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'RandomForest → MAE={mae:.4f} RMSE={rmse:.4f} R²={r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1584cc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost → MAE=57.9307 RMSE=216.8824 R²=0.9439 | n_estimators=300\n"
     ]
    }
   ],
   "source": [
    "# Optional: XGBoost (graceful if not installed)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    # Fast mode controls\n",
    "    try:\n",
    "        FAST_TRAIN\n",
    "    except NameError:\n",
    "        FAST_TRAIN = False\n",
    "    n_estimators = 300 if FAST_TRAIN else 500\n",
    "    xgbr = xgb.XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgbr.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    yx = xgbr.predict(X_test)\n",
    "    mae_x = mean_absolute_error(y_test, yx)\n",
    "    rmse_x = np.sqrt(mean_squared_error(y_test, yx))\n",
    "    r2_x = r2_score(y_test, yx)\n",
    "    print(f'XGBoost → MAE={mae_x:.4f} RMSE={rmse_x:.4f} R²={r2_x:.4f} | n_estimators={n_estimators}')\n",
    "except Exception as e:\n",
    "    print('XGBoost not available or failed to train:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97bb4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f_/xz3vy0ns22jdm26zz2tpj82w0000gn/T/ipykernel_13868/2266332149.py:7: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>square_id</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>0.429318</td>\n",
       "      <td>0.511431</td>\n",
       "      <td>0.305492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>2801</td>\n",
       "      <td>0.443042</td>\n",
       "      <td>0.535801</td>\n",
       "      <td>-0.463523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>5239</td>\n",
       "      <td>0.630211</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>-2.866016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1207</td>\n",
       "      <td>0.814531</td>\n",
       "      <td>0.975162</td>\n",
       "      <td>0.220599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>5339</td>\n",
       "      <td>0.780687</td>\n",
       "      <td>1.455482</td>\n",
       "      <td>-1.041601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      square_id       MAE      RMSE        R2\n",
       "111         112  0.429318  0.511431  0.305492\n",
       "2800       2801  0.443042  0.535801 -0.463523\n",
       "5238       5239  0.630211  0.652103 -2.866016\n",
       "1206       1207  0.814531  0.975162  0.220599\n",
       "5338       5339  0.780687  1.455482 -1.041601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/hamza/Documents/MobilCom/mobile_dataset/results/per_cell_metrics.csv\n",
      "Saved: /Users/hamza/Documents/MobilCom/mobile_dataset/results/pred_vs_actual_cell_1122.png\n"
     ]
    }
   ],
   "source": [
    "# Evaluation: per-cell metrics and plots\n",
    "test_eval = test_df[['square_id','time_interval', target]].copy()\n",
    "test_eval['pred_rf'] = y_pred\n",
    "\n",
    "def rmse_f(a,b): return float(np.sqrt(np.mean((a-b)**2)))\n",
    "per_cell = (test_eval.groupby('square_id')\n",
    "           .apply(lambda g: pd.Series({\n",
    "               'MAE': mean_absolute_error(g[target], g['pred_rf']),\n",
    "               'RMSE': rmse_f(g[target].to_numpy(), g['pred_rf'].to_numpy()),\n",
    "               'R2': r2_score(g[target], g['pred_rf'])\n",
    "           }))\n",
    "          .reset_index())\n",
    "display(per_cell.sort_values('RMSE').head())\n",
    "out_csv = RESULTS / 'per_cell_metrics.csv'\n",
    "per_cell.to_csv(out_csv, index=False)\n",
    "print('Saved:', out_csv)\n",
    "\n",
    "# Example predicted vs actual plot for a sample cell (correct alignment by cell & time)\n",
    "sample_cell = int(per_cell.sort_values('RMSE').iloc[0]['square_id']) if len(per_cell) else int(test_df['square_id'].iloc[0])\n",
    "# Select predictions already aligned per row, then filter by the chosen cell\n",
    "g = test_eval[test_eval['square_id'] == sample_cell].copy()\n",
    "g = g.sort_values('time_interval')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(g['time_interval'], g[target], label='Actual')\n",
    "plt.plot(g['time_interval'], g['pred_rf'], label='RF Pred', alpha=0.8)\n",
    "plt.title(f'Cell {int(sample_cell)} — Actual vs Predicted')\n",
    "plt.legend(); plt.tight_layout()\n",
    "pv = RESULTS / f'pred_vs_actual_cell_{int(sample_cell)}2.png'\n",
    "plt.savefig(pv); plt.close(); print('Saved:', pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca758e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: /Users/hamza/Documents/MobilCom/mobile_dataset/results/rf_model.pkl\n",
      "Saved metrics: /Users/hamza/Documents/MobilCom/mobile_dataset/results/metrics.json\n"
     ]
    }
   ],
   "source": [
    "# Save model and summary metrics\n",
    "metrics = {}\n",
    "# RF\n",
    "try:\n",
    "    metrics['rf_mae']  = float(mae)\n",
    "    metrics['rf_rmse'] = float(rmse)\n",
    "    metrics['rf_r2']   = float(r2)\n",
    "except NameError:\n",
    "    pass\n",
    "# XGB\n",
    "try:\n",
    "    metrics['xgb_mae']  = float(mae_x)\n",
    "    metrics['xgb_rmse'] = float(rmse_x)\n",
    "    metrics['xgb_r2']   = float(r2_x)\n",
    "except Exception:\n",
    "    pass\n",
    "# Baseline - Naive\n",
    "try:\n",
    "    metrics['baseline_naive'] = {\n",
    "        'mae': float(mae_b), 'rmse': float(rmse_b), 'r2': float(r2_b)\n",
    "    }\n",
    "except Exception:\n",
    "    pass\n",
    "# Baseline - Moving Average (3/6/12)\n",
    "try:\n",
    "    metrics['baseline_ma'] = {\n",
    "        'k3': ma_metrics.get(3, {}),\n",
    "        'k6': ma_metrics.get(6, {}),\n",
    "        'k12': ma_metrics.get(12, {})\n",
    "    }\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "MODEL_PATH = RESULTS / 'rf_model.pkl'\n",
    "try:\n",
    "    joblib.dump(rf, MODEL_PATH)\n",
    "    print('Saved model:', MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print('Model save skipped:', e)\n",
    "\n",
    "with open(RESULTS / 'metrics.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print('Saved metrics:', RESULTS / 'metrics.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03dbef",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Zaman bazlı çapraz doğrulama (expanding window) ekleyin.\n",
    "- XGBoost’u kalibre edip RF ile kıyas tablosu üretin.\n",
    "- Prophet/ARIMA’yı en iyi kapsamalı 5–10 hücrede deneyin.\n",
    "- Hata analizi grafiklerini (residual dağılımı, zaman/hucre ısı haritaları) ekleyin.\n",
    "- Sonuçları raporlayıp sunum slaytlarını hazırlayın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16ebc70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV folds: [('2013-11-04T11:00:00.000000000', '2013-11-05T00:00:00.000000000'), ('2013-11-05T00:00:00.000000000', '2013-11-05T13:00:00.000000000'), ('2013-11-05T13:00:00.000000000', '2013-11-06T02:00:00.000000000')]\n",
      "CV summary: {\n",
      "  \"rf\": {\n",
      "    \"cv_mae_mean\": 52.72824542732252,\n",
      "    \"cv_mae_std\": 4.222033409879141,\n",
      "    \"cv_rmse_mean\": 144.0123321380179,\n",
      "    \"cv_rmse_std\": 10.895380419782079,\n",
      "    \"cv_r2_mean\": 0.9743349661421989,\n",
      "    \"cv_r2_std\": 0.0037946212608808184,\n",
      "    \"folds\": [\n",
      "      {\n",
      "        \"fold\": 1,\n",
      "        \"mae\": 58.28449840348217,\n",
      "        \"rmse\": 157.24458783137925,\n",
      "        \"r2\": 0.9737936827035827\n",
      "      },\n",
      "      {\n",
      "        \"fold\": 2,\n",
      "        \"mae\": 48.0568707199404,\n",
      "        \"rmse\": 144.23320134317117,\n",
      "        \"r2\": 0.9699818664165729\n",
      "      },\n",
      "      {\n",
      "        \"fold\": 3,\n",
      "        \"mae\": 51.84336715854499,\n",
      "        \"rmse\": 130.5592072395033,\n",
      "        \"r2\": 0.9792293493064415\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"xgb\": {\n",
      "    \"cv_mae_mean\": 63.55168902759841,\n",
      "    \"cv_mae_std\": 7.110552037458202,\n",
      "    \"cv_rmse_mean\": 243.31565096995007,\n",
      "    \"cv_rmse_std\": 29.042737275866486,\n",
      "    \"cv_r2_mean\": 0.9275285337426459,\n",
      "    \"cv_r2_std\": 0.009536366845663625,\n",
      "    \"folds\": [\n",
      "      {\n",
      "        \"fold\": 1,\n",
      "        \"mae\": 73.51820481359668,\n",
      "        \"rmse\": 284.06512878287947,\n",
      "        \"r2\": 0.914475522436446\n",
      "      },\n",
      "      {\n",
      "        \"fold\": 2,\n",
      "        \"mae\": 57.41026545919401,\n",
      "        \"rmse\": 218.48771925464717,\n",
      "        \"r2\": 0.931117759905678\n",
      "      },\n",
      "      {\n",
      "        \"fold\": 3,\n",
      "        \"mae\": 59.726596810004544,\n",
      "        \"rmse\": 227.39410487232357,\n",
      "        \"r2\": 0.9369923188858136\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "Saved: /Users/hamza/Documents/MobilCom/mobile_dataset/results/model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Time-based cross-validation (expanding windows) for RF/XGB\n",
    "import numpy as np, pandas as pd, json\n",
    "from pathlib import Path\n",
    "\n",
    "def make_folds_times(times: pd.Series, cut_points=(0.6,0.7,0.8,0.9)):\n",
    "    t = np.sort(times.unique())\n",
    "    n = len(t)\n",
    "    idx = [int(n*c) for c in cut_points]\n",
    "    folds = []\n",
    "    for i in range(len(idx)-1):\n",
    "        tr_end = t[idx[i]]\n",
    "        val_end = t[idx[i+1]]\n",
    "        folds.append((tr_end, val_end))\n",
    "    return folds\n",
    "\n",
    "def build_xy(df_part, feature_cols, target_col):\n",
    "    X = df_part[feature_cols].values\n",
    "    y = df_part[target_col].values\n",
    "    return X, y\n",
    "\n",
    "# Build folds on the training period only\n",
    "folds = make_folds_times(train_df['time_interval'])\n",
    "print('CV folds:', [(str(a), str(b)) for a,b in folds])\n",
    "\n",
    "cv_results = {'rf': [], 'xgb': []}\n",
    "for fold_i, (tr_end, val_end) in enumerate(folds, 1):\n",
    "    tr = train_df[train_df['time_interval'] <= tr_end]\n",
    "    va = train_df[(train_df['time_interval'] > tr_end) & (train_df['time_interval'] <= val_end)]\n",
    "    X_tr, y_tr = build_xy(tr, features, target)\n",
    "    X_va, y_va = build_xy(va, features, target)\n",
    "    # Optional subsample in Fast Mode\n",
    "    try:\n",
    "        use_fast = bool(FAST_TRAIN)\n",
    "        frac = float(FAST_SAMPLE_FRAC) if 'FAST_SAMPLE_FRAC' in globals() else 1.0\n",
    "    except Exception:\n",
    "        use_fast = False; frac = 1.0\n",
    "    if use_fast and 0.0 < frac < 1.0 and len(X_tr) > 1:\n",
    "        rs = np.random.RandomState(42)\n",
    "        k = max(1, int(len(X_tr)*frac))\n",
    "        idx = rs.choice(len(X_tr), size=k, replace=False)\n",
    "        X_tr, y_tr = X_tr[idx], y_tr[idx]\n",
    "    # RandomForest\n",
    "    rf_cv = RandomForestRegressor(n_estimators=100 if use_fast else 200, max_depth=12 if use_fast else None, min_samples_leaf=5 if use_fast else 1, random_state=42, n_jobs=-1)\n",
    "    rf_cv.fit(X_tr, y_tr)\n",
    "    pr = rf_cv.predict(X_va)\n",
    "    mae_rf = mean_absolute_error(y_va, pr)\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_va, pr))\n",
    "    r2_rf = r2_score(y_va, pr)\n",
    "    cv_results['rf'].append({'fold': fold_i, 'mae': float(mae_rf), 'rmse': float(rmse_rf), 'r2': float(r2_rf)})\n",
    "    # XGBoost (if available)\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        xgb_cv = xgb.XGBRegressor(n_estimators=300 if use_fast else 500, max_depth=8, learning_rate=0.05, subsample=0.8, colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
    "        xgb_cv.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
    "        px = xgb_cv.predict(X_va)\n",
    "        mae_x = mean_absolute_error(y_va, px)\n",
    "        rmse_x = np.sqrt(mean_squared_error(y_va, px))\n",
    "        r2_x = r2_score(y_va, px)\n",
    "        cv_results['xgb'].append({'fold': fold_i, 'mae': float(mae_x), 'rmse': float(rmse_x), 'r2': float(r2_x)})\n",
    "    except Exception as e:\n",
    "        # XGB not installed or failed; skip\n",
    "        pass\n",
    "\n",
    "# Summaries\n",
    "def summarize(name, rows):\n",
    "    import numpy as np\n",
    "    if not rows:\n",
    "        return None\n",
    "    mae = np.array([r['mae'] for r in rows])\n",
    "    rmse = np.array([r['rmse'] for r in rows])\n",
    "    r2 = np.array([r['r2'] for r in rows])\n",
    "    return {\n",
    "        'cv_mae_mean': float(mae.mean()), 'cv_mae_std': float(mae.std()),\n",
    "        'cv_rmse_mean': float(rmse.mean()), 'cv_rmse_std': float(rmse.std()),\n",
    "        'cv_r2_mean': float(r2.mean()), 'cv_r2_std': float(r2.std()),\n",
    "        'folds': rows\n",
    "    }\n",
    "\n",
    "cv_summary = {\n",
    "    'rf': summarize('rf', cv_results['rf']),\n",
    "    'xgb': summarize('xgb', cv_results['xgb'])\n",
    "}\n",
    "print('CV summary:', json.dumps(cv_summary, indent=2))\n",
    "\n",
    "# Save CSV comparison\n",
    "rows = []\n",
    "def row_from(name, summ):\n",
    "    if not summ:\n",
    "        return {'model': name}\n",
    "    return {'model': name, 'cv_rmse_mean': summ['cv_rmse_mean'], 'cv_rmse_std': summ['cv_rmse_std'], 'cv_mae_mean': summ['cv_mae_mean'], 'cv_mae_std': summ['cv_mae_std']}\n",
    "rows.append(row_from('rf', cv_summary['rf']))\n",
    "rows.append(row_from('xgb', cv_summary['xgb']))\n",
    "cmp_df = pd.DataFrame(rows)\n",
    "cmp_path = RESULTS / 'model_comparison.csv'\n",
    "cmp_df.to_csv(cmp_path, index=False)\n",
    "print('Saved:', cmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdff26bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: rf CV RMSE: 144.0123321380179\n",
      "Saved best model as best_model.pkl\n",
      "Updated metrics.json with CV summaries and selection.\n"
     ]
    }
   ],
   "source": [
    "# Select best model based on CV RMSE (lower is better) and update metrics.json\n",
    "import json, os\n",
    "metrics_path = RESULTS / 'metrics.json'\n",
    "try:\n",
    "    with open(metrics_path, 'r', encoding='utf-8') as f:\n",
    "        existing = json.load(f)\n",
    "except Exception:\n",
    "    existing = {}\n",
    "\n",
    "best_name = None\n",
    "best_rmse = float('inf')\n",
    "for name in ['rf','xgb']:\n",
    "    summ = cv_summary.get(name)\n",
    "    if summ and summ['cv_rmse_mean'] < best_rmse:\n",
    "        best_rmse = summ['cv_rmse_mean']\n",
    "        best_name = name\n",
    "\n",
    "existing['cv'] = cv_summary\n",
    "existing['model_comparison'] = {'selected': best_name, 'selected_cv_rmse_mean': best_rmse}\n",
    "print('Selected model:', best_name, 'CV RMSE:', best_rmse)\n",
    "\n",
    "# Save best model artifact if available\n",
    "try:\n",
    "    if best_name == 'rf':\n",
    "        joblib.dump(rf, RESULTS / 'best_model.pkl')\n",
    "    elif best_name == 'xgb':\n",
    "        joblib.dump(xgbr, RESULTS / 'best_model.pkl')\n",
    "    print('Saved best model as best_model.pkl')\n",
    "except Exception as e:\n",
    "    print('Best model save skipped:', e)\n",
    "\n",
    "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(existing, f, indent=2)\n",
    "print('Updated metrics.json with CV summaries and selection.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
